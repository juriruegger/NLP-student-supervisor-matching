firstName,lastName,proposal
Anna,Rogers,"I'm really interested in diving into how language models learn and what kind of knowledge they pick up during their pre-training phase. It’s fascinating to think about how these models can understand and generate human-like text, but I want to dig deeper into the specifics of what they actually know.

For my thesis, I plan to explore the different types of knowledge that these models acquire. This could include everything from grammar and vocabulary to more complex concepts like cultural references or contextual understanding. I think it’s important to break down these elements to see how they contribute to the model's overall performance.

I want to analyze various language models and see how they handle different tasks. By doing this, I hope to uncover patterns in their knowledge and maybe even identify gaps where they struggle. This could help us understand not just how these models work, but also how we can improve them in the future.

Overall, I’m excited about this project because it combines my love for language with my curiosity about technology. I believe that understanding the inner workings of these models can lead to better applications and innovations in the field."
Anna,Rogers,"I’m really interested in diving into how language processing works, especially when it comes to natural language processing (NLP) models. My main focus is to figure out whether these models are actually getting things right for the right reasons. It’s fascinating to think about how they tackle reasoning tasks and what strategies they use to come up with their answers.

I want to explore the different approaches these models take when faced with complex reasoning challenges. Are they genuinely understanding the context, or are they just picking up on patterns without real comprehension? This question really intrigues me because it could have big implications for how we use these models in real-world applications.

By digging into this topic, I hope to uncover what makes these models tick and whether they can be trusted to reason like humans do. I believe that understanding their strategies will not only help improve their performance but also guide us in developing better models in the future. Overall, I’m excited to contribute to this area and see what insights I can find!"
Anna,Rogers,"I’m really interested in exploring how well NLP models hold up when they’re faced with data that’s different from what they were trained on. It seems like a big question in the field right now: can these models actually do their jobs effectively when they encounter new situations? I want to dig into whether they can generalize their skills beyond the training data and what strategies we might use to improve their performance in these scenarios.

I think this topic is super relevant because as we rely more on AI for various applications, understanding their limitations is crucial. I plan to look into different methods that could help enhance their robustness, like tweaking the training process or using diverse datasets. By doing this, I hope to find ways to make these models more reliable and adaptable, which could really benefit their real-world applications. Overall, I’m excited to tackle this challenge and contribute to making NLP technology more effective."
Anna,Rogers,"I'm really interested in diving into the world of Natural Language Processing (NLP) and figuring out how we can make sure these systems are safe to use before they go live. My project will focus on auditing NLP systems and creating clear documentation that outlines when it's okay to deploy them. 

I want to explore the different scenarios and conditions that determine whether an NLP system is reliable and trustworthy. This is super important because as these technologies become more integrated into our daily lives, we need to ensure they don’t cause harm or spread misinformation. 

By examining various case studies and existing frameworks, I plan to identify best practices for evaluating the safety of these systems. I think it’s crucial to have a solid understanding of the potential risks involved and how to mitigate them. 

Ultimately, my goal is to create a comprehensive guide that can help developers and organizations make informed decisions about deploying NLP systems. I believe this project will not only enhance my skills but also contribute to the responsible use of technology in society."
Anna,Rogers,"I’m really interested in exploring how we can make natural language processing (NLP) more sustainable. It seems like a lot of the current models need massive amounts of data and tons of parameters, which isn’t great for the environment or for accessibility. I want to dive into ways we can create effective NLP systems that don’t rely on these huge resources. 

My goal is to investigate alternative methods that can still deliver solid performance without the heavy computational load. I think it’s crucial to find a balance between efficiency and effectiveness, especially as we see more awareness around the environmental impact of tech. 

By focusing on this topic, I hope to contribute to a more responsible approach in the field, making NLP tools available to a wider range of people and organizations. I’m excited to see what innovative solutions we can come up with that prioritize sustainability while still pushing the boundaries of what NLP can do."
Alessandro,Bruni,"I'm really excited about the idea of working on safe robot controllers for my master's thesis. It's super important that robots can operate without causing harm to themselves or their surroundings. There are some cool simulators out there, like Safety Gym from OpenAI, BRAX from Google, and Mujoco from DeepMind, that tackle this issue. 

What I find particularly interesting is how differentiable logics can be used to define safety rules and turn those rules into loss functions for training neural networks. There's this tool called Vehicle that makes it easier to use these differentiable logics alongside popular neural network training frameworks. 

For my project, I want to dive into how these differentiable logics can actually help create safer robot controllers. I think this could lead to some really valuable insights and advancements in the field."
Alessandro,Bruni,"I'm really excited about diving into the world of probability theory and its applications, especially in computer science. There’s so much potential here, from machine learning to cryptography, and I think it’s a fascinating area to explore. I've been working with two cool libraries that focus on probability: MathComp-analysis, which deals with real analysis and includes some of my work on probability, and Infotheo, which started out focused on information theory but has expanded to cover a lot of probability applications.

I have a bunch of project ideas that sit at the crossroads of machine learning, statistics, and probability theory using these libraries. I’d love to collaborate with anyone interested in these topics, so feel free to reach out if you want to brainstorm or work together!"
Alessandro,Bruni,"I want to dive into the world of security protocols for my master's thesis because they play such a huge role in our daily lives. Take TLS, for instance; it’s what keeps our online chats and transactions safe. But there are tons of other protocols out there, and many of them have hidden flaws that can go unnoticed for years. A lot of these issues come from logical errors—basically, things the designers didn’t think could happen when they created the protocol.

I’m really interested in using tools like ProVerif to analyze these protocols. This software lets you model them and automatically check if they meet certain security standards or reveal potential attacks. I think it would be super cool to pick a security protocol that’s interesting and run a formal analysis on it using these automated tools. Often, this kind of work uncovers mistakes in how the protocols are specified or implemented.

For example, I’ve read about how some research has helped improve the EDHOC standard for secure communication in IoT devices, and there were also findings related to flaws in the CAN-bus system used in cars. I’m considering analyzing something like the Apple keychain or Firefox’s password storage, or maybe even a messaging protocol like WhatsApp or Telegram. I’m excited about the possibility of discovering new insights and contributing to the field!"
Alessandro,Bruni,"I'm really interested in diving into the world of secure protocols for my master's thesis. I've noticed that a lot of the tools we have for analyzing these protocols come with some pretty significant limitations. For instance, there are certain properties that can’t be automatically checked, which means we often have to do some manual work to get the proofs right. Plus, there are specific equations that need extra attention, which can be tricky.

One area that really catches my eye is stateful protocols. These are the ones that keep track of their state based on what actions are available, and analyzing them can be quite complex. Another challenge is figuring out how to turn a proven protocol model into secure software. One approach could be to generate actual code from the protocol model that’s secure from the get-go.

I’m passionate about programming languages, software analysis, and compilers, and I believe that tackling security issues is super important in today’s software world. I’m excited about the possibility of working on a thesis that explores these topics further!"
Bernardo Machado,David,"I've been thinking a lot about the privacy issues surrounding cryptocurrencies and smart contracts. Right now, most of them don’t really keep users' identities safe, which means anyone can see who’s sending money to whom. There are a few solutions out there that try to keep everything anonymous, but they often make things super complicated and can clash with financial laws. These laws require that authorities can access a person’s financial history if needed, which makes it tough to balance privacy with compliance.

To tackle this, I want to come up with some solid security definitions for cryptocurrencies and smart contracts that offer better privacy options without being overly complex. I also think it’s crucial to create auditing systems that align with KYC (Know Your Customer) and AML (Anti-Money Laundering) regulations. I’m also curious about looking into state channels, as they might help us develop more efficient protocols.

For this project, I believe it’s a mix of theory and practical work, which is perfect for someone at the master’s level who knows a bit about modern cryptography. But I also think it’s accessible enough for anyone with some software development skills. I’m excited to explore this further and would love to chat about how we can shape the project based on what I’m most interested in."
Bernardo Machado,David,"I’m really interested in diving into the world of blockchain and how it works, especially when it comes to making it more efficient. Right now, a lot of the consensus protocols, like the one used by Bitcoin, have some serious speed issues. They can only handle a handful of transactions per second, which is nothing compared to traditional financial systems that can manage thousands. This bottleneck really limits how we can use blockchain in real-world applications that need to process a lot of transactions quickly.

One idea I’m excited about is blockchain sharding. This approach involves running multiple versions of the blockchain at the same time, with different groups of users managing each one. It’s a way to keep everything consistent while boosting efficiency. Another cool concept is using sidechains, which are like mini blockchains that handle specific tasks while still being linked to the main chain. However, figuring out how to keep everything secure and consistent in these setups is a big challenge.

I’m also curious about alternatives to the traditional Proof-of-Work system, like Proof-of-Stake, which might offer better performance even when running just one instance. 

For my thesis, I’d love to explore these ideas further. I think it would be a great fit for someone at the master’s level, especially if they have a solid grasp of modern cryptography. I’m also open to collaborating with others who have experience in distributed systems programming to test out these protocols in a practical way. Overall, I’m excited about the potential of blockchain and can’t wait to dig deeper into these solutions!"
Bernardo Machado,David,"I've been thinking a lot about blockchain technology and how many of the consensus protocols and applications seem to be thrown together without really thinking about security. This kind of haphazard approach has led to a bunch of vulnerabilities that can be pretty damaging, especially since these systems often deal with a lot of money. When these weaknesses are exploited, it can lead to quick financial losses, which is definitely a big deal.

I want to dive into this issue by focusing on how we can identify specific vulnerabilities in these protocols. While it’s tough to formally prove that these ad-hoc systems are secure, I believe that many companies and users would be more willing to make updates if we can point out the actual problems. Since most blockchain projects are open source, I see a great chance to use practical techniques to analyze the code and find these vulnerabilities.

Once I identify some weaknesses, my plan is to suggest fixes at the protocol level and share my findings responsibly with the development community. I think this approach could really help improve the security of these systems. I have a solid programming background, so I feel ready to tackle the code analysis and testing involved in this project. I’m excited about the potential impact this work could have on the blockchain space!"
Bernardo Machado,David,"I’m really excited to dive into a project on Multiparty Computation (MPC) for my master’s thesis. MPC is a cool way for different parties who don’t trust each other to work together on a program using their private data without revealing anything except the final result. While there are already a bunch of MPC protocols out there, I think there’s a lot of room to make them faster and more efficient, especially for general tasks like computing boolean and arithmetic circuits, as well as for specific uses like machine learning with private data.

One of the main issues I want to tackle is how to reduce the number of rounds needed in these protocols. Since each round takes time, especially over the internet, having too many can really slow things down. I also want to look into how we can better combine protocols for arithmetic and boolean circuits since they work better for different types of algorithms. Another interesting angle is preprocessing, where parties can do most of the heavy lifting before they even know their actual inputs. 

Beyond just improving general protocols, I’m keen to explore how these ideas can be applied to specific areas like machine learning, which could have real-world benefits for users and businesses. I believe this project will involve both some theoretical work, which I’m ready for since I’ve got a solid background in modern cryptography, and practical coding tasks that I think I can handle with my software development skills. I’m looking forward to discussing how we can shape this project based on my interests and what I can bring to the table."
Bernardo Machado,David,"I’m really interested in diving into the world of theoretical cryptography for my master’s thesis. One of the big things I want to explore is what the essential building blocks are for creating more complex cryptographic systems. Two key components that keep popping up are Commitments and Oblivious Transfer. These are super important for developing advanced tasks like Multiparty Computation and Zero-Knowledge Proofs. So, I think it’s crucial to figure out what assumptions we need to build protocols around these concepts and what the limits are when it comes to their efficiency.

To get a better grip on these building blocks and how they fit into the bigger picture of cryptographic protocols, I want to look into different ways to construct them based on various assumptions. I’m also keen on figuring out how to make these protocols more efficient. I believe that by focusing on improving the efficiency of Commitments and Oblivious Transfer, we can really enhance the overall performance of cryptographic systems.

I know this project will involve a lot of theoretical work, which I’m ready for, especially since I have a solid background in modern cryptography. I’m excited about the challenge and can’t wait to see where this research takes me!"
Christian,Hardmeier,"I'm really excited to dive into a project focused on speech processing and handling sensitive information. My plan is to work on transcribing and anonymizing conversations that involve therapists and their patients, which will help in training large language models. This project is in partnership with the VIRTU research group at Region Hovedstadens Psykiatri, and I think it’s a fantastic opportunity to contribute to the field of psychotherapy.

We have access to a ton of audio recordings from therapy sessions, which is a goldmine for creating a dataset. The main hurdles I see are fine-tuning automatic speech recognition models to get the best results from this specific type of data. Plus, I’ll need to figure out how to anonymize the transcriptions effectively, making sure to identify and remove any personal information. I’m really looking forward to tackling these challenges and seeing how we can use this data to enhance psychotherapy practices."
Christian,Hardmeier,"I'm really excited to dive into a project that focuses on understanding and communicating uncertainty in language models. My goal is to explore how the uncertainty metrics we get from these models change based on the confidence levels in the data we use to fine-tune them. To do this, I plan to create some fine-tuning datasets that have different levels of confidence, using a meta-analysis dataset as a starting point. I want to see how the confidence we measure relates to the confidence in the fine-tuning data itself.

Another key part of my project is about making sure that the uncertainty expressed by a language model matches up with the numerical uncertainty we can measure using machine learning techniques. I think it’s super important for users to understand the uncertainty in a way that feels intuitive, so I want to train a large language model to align its expressed uncertainty with what it actually ""feels.""

I also want to dig into the difference between uncertainty in meaning and uncertainty in form. When we look at uncertainty at the token level, it can get a bit messy because it mixes up the model's uncertainty about the facts with its uncertainty about how to phrase things. Depending on what we’re using the model for—like grammar checking versus answering questions—one type of uncertainty might be more relevant than the other. There are some metrics out there that try to separate these two aspects, like semantic entropy, and I’m eager to see how effectively we can distinguish between them and get reliable estimates for each type of uncertainty. Overall, I think this project could really shed light on how we understand and communicate uncertainty in language models, and I can’t wait to get started!"
Christian,Hardmeier,"I want to dive into the world of toxic speech and how it affects different groups of people. My plan is to focus on a specific type of harmful language and really break down what makes it toxic. I think it’s super important to understand the unique traits of this speech so that I can create models that can spot it and pinpoint exactly what makes it harmful.

I’ve seen some interesting projects before that looked at things like dehumanizing language and threats, and I think there’s a lot of room to expand on those ideas. But I’m also open to exploring a completely different angle if it feels right. 

One thing that stands out to me is how toxic language often targets specific groups, like certain demographics. For my project, I want to choose a particular group that frequently faces this kind of negativity and develop ways to automatically identify the toxic language aimed at them. I’m really interested in figuring out how toxicity can vary depending on who it’s directed at and labeling those specific traits. This project feels important to me because I believe understanding and addressing these issues can make a real difference."
Christian,Hardmeier,"I want to dive into the topic of referring expressions and how they can be pretty ambiguous. For example, take the sentence “The bomb exploded violently. It created a huge crater.” The word “It” could mean either the bomb or the explosion itself, which can be confusing. My goal for this project is to create a model that can handle this ambiguity without forcing a clear-cut answer. 

I’m also interested in how different languages deal with referring expressions. Each language has its own way of choosing how to refer to things, and you can really see this when you look at translations of the same text. For my project, I plan to develop some automatic methods using neural machine translation or large language models to help align these referring expressions across different languages, even when the translations aren’t direct. This topic really excites me because it combines language, technology, and the nuances of communication, which I find fascinating!"
Dan Witzner,Hansen,"I'm excited to propose a project where I’ll create a new domain-specific language (DSL) that’s inspired by LaTeX. My goal is to make it user-friendly and straightforward, while still being powerful enough to handle macros and organize content nicely in Jupyter Notebooks. 

Here’s what I’m aiming to achieve: First, I want to develop a simple and intuitive syntax, using tools like Lark for Python to help with parsing and interpreting the language. I also plan to include features for creating macros and other customizable elements, so users can easily reuse components. 

Another key aspect is making sure this DSL works seamlessly with the JupyterBook environment. This way, users can embed content created with the DSL right into their notebooks, while still having the flexibility to use Python and Markdown cells. Ultimately, I believe this DSL will make it easier to share and define content on platforms like iml.itu.dk, leading to a smoother experience when integrating custom structures into Jupyter projects. I’m really looking forward to diving into this and seeing how it can enhance the way we work with Jupyter!"
Martin,Aumüller,"I'm really interested in diving into the topic of privacy-preserving similarity search for my master's thesis. With all the concerns about user data leaks, especially on social media and big platforms, I think it’s super important to look closely at how data is handled to prevent any breaches. My goal is to explore the privacy challenges and techniques that can help keep user information safe in similarity search systems. These systems are crucial for various applications like recommendation engines, machine learning, and information retrieval, which often deal with sensitive data like user preferences or even medical records.

I see a few different paths I could take with this project. One idea is to analyze potential attack scenarios on similarity search tools. This would involve looking at different methods for similarity search, like locality-sensitive hashing, tree-based approaches, and similarity graphs, and figuring out how they hold up against various threats, especially in areas like recommendation systems or deep learning.

Another direction I could go is to investigate existing techniques that focus on privacy-preserving similarity search and assess how secure they really are. I’d love to work on creating a library for similarity search that has solid security guarantees.

Additionally, I could compare two current methods to see how they stack up in terms of privacy protection and performance. For instance, I could look at the work done by Pagh and Stausholm (2020) and see how it relates to the findings of Aumüller et al. (2020). There have already been a couple of master's theses that touched on building privacy-preserving similarity search tools, so extending one of those could be a great option too. Alternatively, I could also consider doing a survey of the existing technologies as a starting point for a bachelor thesis or research project. Overall, I’m excited about the potential impact of this work and can’t wait to get started!"
Michele,Coscia,"I’m really excited about diving into a project that looks at how culture is produced and shared through different networks. I want to explore connections between artists and bands using data from Discogs, or maybe even map out relationships in movies using IMDb. There’s also a lot of potential in analyzing citation networks from various artworks or literature, and I think character connections in books or graphic novels could be super interesting too. 

I’m particularly drawn to the idea of using Wikipedia to create networks of notable figures and see how they’re all linked. My goal is to build networks that come with detailed information about each node, which will help me investigate different aspects of cultural production. I’m thinking about things like how genres evolve over time, looking at cultural trends across different periods, or even examining geographical influences on culture. This project really excites me because it combines my love for culture with data analysis, and I can’t wait to see what insights I can uncover!"
Michele,Coscia,"I've been working on a way to figure out how polarized political discussions are on platforms like Facebook and Twitter. So far, I've created a method that works well for just two opposing views. But what about situations where people have a mix of opinions, like supporting different political parties at the same time? I think this project could really use some cool NLP tools to create word embeddings, like GPT or Word2Vec, along with some machine learning techniques like PCA, NNMF, and t-SNE. This isn't just for data nerds; I believe it can help us understand the complexity of online conversations better!"
Michele,Coscia,"I want to dive into how we can use OpenStreetMap data to explore urban networks. By looking at the variety of points of interest in different cities, I think we can really get a sense of what makes a place livable. This could help us come up with some fresh ways to measure how enjoyable a city is to live in. I’m excited about the idea of analyzing this data to see how diverse amenities can impact the overall vibe of urban areas. It feels like there’s a lot of potential here to uncover new insights about city life!"
Michele,Coscia,"I’m really interested in exploring how where we live affects our opportunities, especially in developing countries. I want to dive into a new dataset that looks at the development levels of different areas. My goal is to see how wealth is connected to the places people call home. 

Additionally, I’m curious about how lockdowns have impacted people's lives. When mobility is restricted, do all communities feel the pinch equally, or do those in low-income areas face tougher challenges? I think this is an important topic, especially considering how the pandemic has changed our daily lives. Understanding these dynamics could shed light on the inequalities that exist and help inform future policies."
Michele,Coscia,"I'm really excited about the idea of creating a new library for network analysis using Torch. I've been exploring Torch Geometric, and I think it’s a fantastic tool for graph learning, especially with its GPU capabilities. While there are some GPU options available for Networkx, I believe there's a real opportunity to build a more comprehensive library that focuses on GPU computing from the start. 

I’d love to dive into this project by developing and testing several key network analysis functions. This topic really interests me because I see a lot of potential for improving how we handle graph data, and I think my work could contribute to making these processes faster and more efficient. Plus, it would be a great way to deepen my understanding of both network analysis and GPU programming."
Michele,Coscia,"I’ve been working on this cool project where I’ve developed an algorithm that takes a network and figures out the rules that connect everything by looking for patterns that show up a lot. My main question is: if we have these rules, can we create a brand-new network that resembles the original one we got the rules from? I think this is super interesting because it could help us understand how networks work and maybe even allow us to design new ones based on existing structures. I’m excited to dive deeper into this and see what kind of networks we can come up with!"
Patrick,Bahr,"I'm really excited about the idea of creating a functional reactive programming language that can be embedded into an existing language like Haskell, F#, or Scala. The challenge here is to cleverly work with the type system of the host language so that it can effectively support the type system of the reactive programming language I want to build. 

What’s cool about this project is that by embedding my language, I can leverage all the awesome features and libraries that come with the host language. This means that users can write programs in my new language while still taking advantage of everything the host language has to offer. I think this could open up a lot of possibilities for developers who want to work with reactive programming without having to start from scratch. 

I’m really looking forward to diving into this project because I believe it could make reactive programming more accessible and powerful for a wider audience. Plus, it’ll be a great way to deepen my understanding of type systems and functional programming concepts."
Patrick,Bahr,"I'm really excited about the idea of creating a compiler for a functional reactive programming language. My plan is to build a complete system that includes a parser, a type checker, and a code generator. This project really appeals to me because it gives me the chance to explore the language design and implement some cool features. 

I’m particularly interested in diving into type inference and optimizations, as I think they can make a huge difference in how the language performs. Plus, I’d love to experiment with advanced type system features and find ways to manage memory more efficiently. 

If I find that the project is getting too big, I might narrow my focus to just one part, like type inference, to really dig deep into that aspect. Overall, I think this project will not only help me learn a lot about compilers but also give me a chance to be creative and innovative in how I approach the language."
Patrick,Bahr,"I want to dive into a project where I can use a functional reactive programming language to build something interesting, like a GUI framework, a game, or even a library for creating smooth animations and visualizations. I’m really curious about how the unique type systems in these languages affect the way we develop software. It’s fascinating to think about how these non-traditional approaches can change the way we tackle problems and design systems. By working on this project, I hope to not only create something cool but also gain insights into the practical implications of using these languages in real-world applications. This topic really excites me because I love exploring new ways to code and see how different programming paradigms can shape the development process."
Patrick,Bahr,"I'm really interested in diving into property-based testing for my master's project. Basically, this method involves defining certain properties that a program should meet—like ensuring that sorting a list twice gives you the same result as sorting it just once. The idea is to create a tool or library that can automatically test these properties by generating random inputs.

What makes this project exciting for me is the focus on reactive programming, which can be pretty tricky to test because of its interactive nature. One of the biggest hurdles I see is figuring out how to create a clear and effective language for expressing these properties. I want to tackle this challenge and come up with a solid solution that helps programmers test their reactive applications more easily."
Patrick,Bahr,"I want to dive into the world of compilers for my master's project. Compilers are super intricate pieces of software, and they often have tiny optimizations that can be tricky to get right. It’s really important to nail this down because any bugs in a compiler can mess up all the software built on top of it. The problem is, finding these bugs just through regular testing can be a real challenge.

One interesting way to tackle this is by formally verifying that a compiler works as it should based on its specifications. This means we can derive the compiler directly from its specs, kind of like how you simplify math problems step by step. To help avoid mistakes during this process, we can use tools like Coq or Agda, which check for errors and can automate some of the simpler steps. But here’s the catch: these tools can be pretty general and make the whole process feel tedious and hard to follow.

That’s why I’m excited about this project! I want to create a tool that can help check and even automate parts of the process of deriving compilers from their specifications. I think this could make things a lot smoother and more efficient, and I’m really looking forward to exploring this area further."
Peter,Sestoft,"I'm really excited about the idea of creating a type system for functions defined in spreadsheets, specifically focusing on Funcalc. Funcalc is a tool that’s been discussed in Sestoft's book on spreadsheet technology, and I think there’s a lot of potential to enhance how these functions work. 

The main goal of my project is to come up with a type system that can make these sheet-defined functions safer and faster. One of the big issues right now is that there’s a lot of unnecessary overhead when it comes to boxing values during function calls, which can slow things down. I’ve seen some interesting work done by Poul Broennum on this topic in a previous project, and I believe I can build on that foundation. 

I’m really passionate about this because I think improving the efficiency of spreadsheets can have a huge impact on how people use them for data analysis and decision-making. Overall, I’m looking forward to diving into this project and seeing how I can contribute to making spreadsheet functions more effective!"
Peter,Sestoft,"I’m really excited to dive into a project focused on GPGPUs, which are basically supercharged graphics cards that can handle a lot more than just rendering images. These powerful tools can run certain calculations way faster than regular CPUs—like 10 to 300 times quicker! To get the most out of them, you need to use specific programming techniques and libraries like Nvidia CUDA or OpenCL.

For my thesis, I want to work on implementing some numerical computations, especially in linear algebra. I think it’ll be fascinating to see how these computations perform on GPGPUs compared to traditional methods. I’ll also be looking into ways to optimize their speed, which should be a fun challenge. Overall, I’m really looking forward to exploring this tech and seeing what kind of performance gains I can achieve!"
Peter,Sestoft,"I'm really excited about the idea of creating specialized collection libraries. The C5 library for C#/.Net 2.0 is super powerful and packed with features like sublist views, update events, and persistent trees. However, one downside is that it can be a bit heavy on memory since it includes a lot of functionality that not every user needs. 

For my project, I want to dive into how we can automatically generate or pick out just the parts of the library that are actually useful for specific applications. By doing this, I hope to cut down on memory usage and boost performance. This topic really interests me because I believe optimizing libraries can make a big difference in how efficiently programs run, and I’m eager to explore ways to make this happen."
Peter,Sestoft,"I'm really interested in exploring how run-time code generation works in Java and C#. Both the Java platform from Oracle and the .NET framework from Microsoft have some cool features that let programs create and run bytecode on the fly. This capability could lead to some exciting new ways to handle things like serialization and deserialization, communication protocols, encryption, and even image processing techniques. I think diving into these areas could reveal some innovative solutions and enhance performance in various applications."
Rob,van der Goot,"I'm really interested in exploring how we can improve NLP models by training them on data from different sources. It seems like knowing where the text comes from could really help the model understand the context better. There are some cool techniques out there, like using dataset embeddings, where you can tag the data with something like [SOCIAL] or [NEWS] at the beginning. Another idea is to have the model guess the source of the text as an extra task while it's learning. While these approaches have shown some good results in separate tests, I noticed that they haven't really been compared side by side in a consistent way. I think diving into this could reveal some valuable insights and help enhance how these models work overall."
Rob,van der Goot,"I'm really interested in exploring the idea of lexical normalization, which is all about changing non-standard language into standard language at the word level. While a lot of research has focused on Twitter data, I think there’s a whole world of non-standard language out there that hasn’t been tapped into yet. 

For my project, I want to dive into two main questions: first, how does the effectiveness of normalization drop when we look at different types of language beyond Twitter? And second, what can we do to create stronger models for lexical normalization? 

I’ve found some existing datasets, like those from the MultiLexNorm project, which could be super helpful for this. My plan includes gathering and annotating data, and luckily, the annotation process for this kind of work is pretty quick. I’m excited to see what insights I can uncover!"
Rob,van der Goot,"I want to explore how we can use agents to adapt children's cartoons for different languages while keeping cultural nuances in mind. Cartoons are awesome tools for language learning, but they usually only come in a handful of languages. Translating them into other languages can be super costly and complicated. It’s not just about translating words; we need to capture the context and the way people actually talk, which is different from the usual translation data we have. Plus, we need to think about how to convert text to speech effectively. Each of these steps could really benefit from specific NLP models or agents. One big hurdle I see is figuring out how to evaluate the quality of these adaptations, since we might need human feedback to get it right. I'm really excited about this project because I think it could make language learning more accessible and fun for kids everywhere!"
Rob,van der Goot,"I've been really intrigued by the advancements in sequence-to-sequence (seq2seq) models lately. It seems like they’re becoming super effective, especially since a recent study pointed out that they can match the performance of traditional sequence classification models by turning tasks into sequence generation challenges. However, I think there’s still a gap in how these two approaches are compared. 

For my thesis, I want to dive deeper into this by directly comparing an auto-encoder language model with a generative model. I believe this could shed light on their strengths and weaknesses in tasks like sequence tagging and structure parsing. I’m excited about this topic because understanding how these models stack up against each other could really help in choosing the right approach for different applications. Plus, it’s fascinating to explore how we can unlock the full potential of seq2seq models in practical scenarios."
Rob,van der Goot,"I've been thinking a lot about how NLP models struggle with grasping cultural aspects, and I really want to dive into this for my thesis. It seems like there’s a lot of room for improvement in this area. One idea I have is to explore how we can predict cultural dimensions—like those from Hofstede—just by analyzing texts. Another angle could be to find ways to integrate this cultural info into the training and prediction processes of these models. I find this topic super interesting because understanding culture can really change how we interpret language, and I think it could lead to more accurate and nuanced NLP applications."
Rob,van der Goot,"I'm really interested in exploring how temperature affects the way language models generate text. When we use these models, we want the output to feel natural and human-like, right? Well, temperature is a key factor that helps adjust how random or smooth the text can be. It plays a big role in shaping the ""style"" of what the model produces.

For my project, I want to dive into how different temperature settings impact the human-like quality of the text generated. I plan to have people evaluate the outputs to see how they perceive the text based on the temperature used. Additionally, I’ll be experimenting with various decoding methods in language generation, especially focusing on Transformers. I think this topic is super fascinating because it combines technology with something as nuanced as human communication, and I’m excited to see what I can uncover!"
Rob,van der Goot,"I’m really interested in exploring how we can improve the training process for neural models, especially in natural language processing. A common practice is to use a development set to figure out when to stop training, but I’ve noticed that this method has its drawbacks. There’s been some talk about the issues with relying too heavily on train-dev-test splits, and I think it’s worth digging deeper into this.

I’ve come across a few different strategies for deciding when to stop training or how to choose the best model. For instance, one approach is to just train for a set number of steps, while another looks at the training loss to make that call. However, as far as I can tell, no one has really compared these methods head-to-head yet. 

I’m excited to dive into this topic because I believe that understanding these different strategies could really help in making neural models more effective, especially when it comes to tasks like cross-lingual transfer. I think this project could shed some light on which methods work best and why, and I’m eager to contribute to this area of research."
Rob,van der Goot,"I've been thinking a lot about how different social backgrounds affect the way we use language, especially in online spaces. There’s been some cool research showing that knowing where a piece of text comes from can really help with natural language processing tasks. But what I find interesting is that we still don’t fully understand which specific social factors, like age or gender, actually influence how people communicate.

I want to dive into this by looking at social media data, which has been annotated recently and could really shed some light on these patterns. For instance, there are studies that explore how men and women might use language differently, like how they structure sentences or choose words. I think it would be fascinating to see how these differences play out across various demographics, especially when it comes to things like age and gender.

By focusing on these aspects, I hope to uncover some meaningful insights into how our backgrounds shape our language use online. This topic really excites me because it connects language, technology, and social issues, and I believe it could lead to a better understanding of communication in our digital world."
Rob,van der Goot,"I'm really interested in exploring how language models learn to respond to different tasks, especially through something called instruction tuning. Lately, there’s been a lot of focus on creating datasets for English, but when it comes to other languages, there’s hardly any manually created data available. Most of the time, people just translate instructions from English or use outputs from bigger, more reliable language models. What I find intriguing is that there hasn’t been a thorough comparison of these methods yet. For my project, I want to dive into how much data is needed and what the costs are for creating datasets using these different approaches. This could really shed light on the best ways to handle instruction tuning for various languages."
Rob,van der Goot,"I’m really interested in exploring how we can make social media language easier to understand across different languages. Lexical normalization is all about taking the slang and shorthand we see online and turning it into something more standard. Most of the research so far has focused on just one language at a time, which seems pretty limiting. 

In 2021, a project called MultiLexNorm came out, and it’s a game-changer because it includes normalization datasets for 13 different language variations. A bunch of models were tested on this new benchmark, but they all trained separate models for each language. I think there’s a better way to approach this. Some of those models could actually work together in a multi-lingual setup, which might make things more efficient and help us tackle languages that don’t have much annotated data yet.

I want to dive deeper into this idea and see how we can leverage these models to improve performance across multiple languages. I believe this could really help in making social media communication clearer for everyone, no matter what language they’re using. Plus, it’s a fascinating challenge that combines tech and linguistics, which I’m super passionate about!"
Rob,van der Goot,"I'm really excited to dive into a project focused on tokenizing social media data for my master's thesis. While tokenization is pretty straightforward in most traditional text, social media presents a whole different challenge. I want to tackle this by building a multilingual dataset and model specifically for this purpose.

To kick things off, I plan to gather original posts from the Multi-LexNorm dataset. From there, I’ll create a solid gold standard dataset that compares the original text with its tokenized version. I think it’s crucial to evaluate the current tokenization tools out there, and I’m also keen on developing my own tokenizer to see how it stacks up.

I’ve come across some interesting work in this area, like Universal Word Segmentation and tools like twokenize and nltk.TweetTokenizer, which I’ll definitely look into. Overall, I believe this project will not only enhance my skills but also contribute to a better understanding of how to handle social media text in natural language processing."
Rob,van der Goot,"I'm really excited to dive into a project focused on language identification, which is a key area in natural language processing (NLP). While it seems like this topic has been tackled, I’ve noticed that most tools out there only cover about 100 languages, and many aren’t even accessible to the public. That’s where my interest lies—there’s so much more potential to explore!

For my thesis, I want to work with the LTI LangID Corpus, which includes over 1300 languages. My main question is: how can we effectively manage such a huge range of languages and the different features that come with them? I think this is a fascinating challenge, especially considering how diverse language data can be.

I’ve come across some interesting previous research that could guide my work, like studies on improving language identification for a large number of languages and creating efficient models for mixed-language texts. I believe that by building on these ideas, I can contribute something valuable to the field. Overall, I’m eager to tackle this project and see what innovative solutions I can come up with!"
Rob,van der Goot,"I've been thinking a lot about language identification, especially how most models are usually tested in just one area. It seems like a missed opportunity because there’s a lot of potential to see how these models perform across different contexts. I want to dive into creating a cross-domain dataset that can help evaluate how well current language identification models hold up when faced with varied types of text.

I find this topic super interesting because language is so diverse, and understanding how well these models can adapt to different domains could really improve their effectiveness. Plus, there are some cool resources out there that I could use, like the Accurate Language Identification of Twitter Messages and the MassiveSumm dataset, which is huge and covers multiple languages. I also came across the LTI LangID Corpus and Fandom Wiki’s content, which could provide a lot of variety for testing.

By putting together this dataset, I hope to shed some light on the strengths and weaknesses of existing models. It could lead to better tools for identifying languages in different settings, which is something I’m really passionate about."
Rob,van der Goot,"I’m really excited to dive into a project focused on dependency parsing, especially using Danish social media data. Basically, dependency parsing is all about figuring out how words in a sentence relate to each other, and I think it’s super interesting to see how this works in a more casual context like social media. 

I’ve noticed that while a lot of languages have been explored through the Universal Dependencies project, Danish hasn’t really been given the same attention, especially when it comes to non-standard language use. Recently, we gathered some unique data samples called DaN+, and I’m curious to see how well current parsing methods can handle them.

For my thesis, I want to annotate a small chunk of this Danish social media data to test out different parsers. I’m also keen to explore various ways to tweak these parsers to improve their performance. Some ideas I’m considering include looking at the challenges of annotating and parsing informal language, especially when it mixes different languages, and comparing methods for parsing languages that don’t have a lot of resources available. 

I’m particularly interested in how cross-lingual parsing could work, especially with training on multiple treebanks. I think this project could really shed light on how we can better understand and process low-resource languages, and I can’t wait to get started!"
Rob,van der Goot,"I’m really excited to dive into a project on morphological tagging for my master’s thesis. Basically, this involves figuring out how to label words based on their structure, which can get pretty complex since a single word might have multiple labels. There are a bunch of different methods out there, but it’s not always clear which one works best in different scenarios.

For this project, I plan to use the Universal Dependencies dataset, which has a ton of languages with morphological tags already annotated. I’m thinking about using the MaChAmp toolkit, but I might also try building a BiLSTM tagger from scratch to really get a feel for how it all works.

I want to explore at least three main strategies for tagging. First, I could predict all the tags as one combined label, similar to how we do with POS tagging but with more complexity. Another approach would be to treat the tagging like a sequence prediction task, kind of like how machine translation works. Lastly, I’m interested in looking at it as a multilabel prediction problem, where I’d get probabilities for each label and then decide on a cutoff point.

I’ve come across some interesting readings, like the SIGMORPHON 2019 Shared Task, which could really help guide my research. I’m looking forward to seeing what I can discover in this area!"
Rodrigo Moreno,Garcia,"I'm really excited about the idea of diving into large-scale co-evolution within a massively multi-agent game setting. I want to use the Neural MMO environment, which I found through OpenAI, to explore how huge populations of neural network-driven agents can evolve together. 

My main focus will be on figuring out what conditions lead to fascinating group dynamics among these agents. I’m curious about what environmental factors might push them to develop into different species or even start working together. It’s intriguing to think about how competition and collaboration can shape their behaviors and interactions. 

By studying these dynamics, I hope to uncover some cool insights into how complex social structures can emerge in artificial environments. This project really interests me because it combines my passion for AI with the challenge of understanding how cooperation and competition can coexist in a digital ecosystem. I can’t wait to see what I discover!"
Rune Møller,Jensen,"I'm really excited to dive into a project focused on optimizing how we stow containers on ships. The main idea is to come up with new algorithms that can help with planning the stowage of containers on vessels. Since this problem is super complex and can't be solved perfectly, I want to create some quick and reliable approximation methods instead. There are so many different approaches I could explore, like using specific heuristics, large neighborhood searches, and even integer programming. I’m also interested in looking into hierarchical decompositions and symbolic representations to see how they can help streamline the process. This topic really grabs my attention because it combines practical challenges with innovative problem-solving, and I can’t wait to see what I can come up with!"
