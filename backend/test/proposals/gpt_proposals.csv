firstName,lastName,proposal
Anna,Rogers,"I want to explore the types of knowledge that language models pick up during pre-training. My goal is to understand what these models actually learn and how they process information. I’d like to dive into the different kinds of knowledge, like factual, linguistic, or common sense, that these models acquire. To do this, I plan to analyze the models' responses and see how they handle various tasks or questions. By examining their outputs, I hope to identify patterns and insights into their learning process. This could help us better understand the strengths and limitations of language models and improve their applications."
Anna,Rogers,"I'm interested in exploring whether NLP models perform well for the right reasons, especially when tackling reasoning tasks. I want to dive into the strategies these models use and figure out if they're genuinely understanding the tasks or just finding shortcuts. My plan is to analyze how these models approach different reasoning challenges and identify the strategies they employ. By doing this, I hope to uncover whether their success is due to true comprehension or if they're relying on patterns that don't reflect real understanding. This could help improve how we design and evaluate NLP models in the future."
Anna,Rogers,"I want to explore how well NLP models perform when they're faced with tasks outside their training data. My goal is to understand their robustness and generalization capabilities. I'll investigate whether these models can handle unexpected inputs and still deliver reliable results. To do this, I plan to test various models on data that differs from what they were trained on and analyze their performance. I also want to identify strategies to improve their adaptability, ensuring they remain effective even when encountering new or unusual data. This research could help enhance the reliability of NLP applications in real-world scenarios."
Anna,Rogers,"I want to explore how we can effectively audit and document NLP systems to determine when they're safe to deploy. My goal is to identify specific scenarios where these systems perform reliably and ensure they meet safety standards. I'll focus on creating a framework that helps assess the risks and limitations of NLP models in various contexts. By doing this, I aim to provide clear guidelines for when and how these systems can be used responsibly. This project will involve testing different models, analyzing their outputs, and documenting findings to establish best practices for deployment."
Anna,Rogers,"I want to explore how we can create efficient NLP systems that perform well without needing massive amounts of data and parameters. My goal is to find ways to make these systems more sustainable and accessible. I’d like to investigate techniques that reduce the size and complexity of models while maintaining their effectiveness. This involves experimenting with different approaches to model training and data usage. By focusing on sustainability, I hope to contribute to making NLP technology more environmentally friendly and widely usable."
Alessandro,Bruni,"I want to explore how we can train robot controllers to be safe, ensuring they don't harm themselves or their surroundings. There are simulators like Safety Gym, BRAX, and Mujoco that help with this, but I’m particularly interested in using differentiable logics. These allow us to turn safety rules into a loss function for training neural networks. I plan to use a tool called Vehicle, which integrates these logics into standard neural network training setups. My goal is to see how effectively differentiable logics can create safer robot controllers."
Alessandro,Bruni,"I want to explore how probability theory can be formalized using the Coq Proof Assistant. Probability theory is crucial in areas like machine learning, statistical algorithms, and cryptography. I've been working with two libraries that are perfect for this: MathComp-analysis, which focuses on real analysis and includes probability, and Infotheo, originally for information theory but now covering more probability applications. I'm excited to dive into projects that sit at the intersection of machine learning, statistics, and probability theory using these tools. If you're interested in these topics, let's connect and discuss potential projects!"
Alessandro,Bruni,"I want to dive into analyzing a security protocol, something that's crucial in our everyday digital interactions. While TLS is well-known for securing internet communications, there are many other protocols out there, and some have hidden flaws that go unnoticed for years. These flaws often stem from logical errors that designers didn't anticipate. I plan to use tools like ProVerif to model a specific protocol and automatically check if it meets certain security standards or if there are vulnerabilities. This approach has been successful in the past, like when issues were found in the EDHOC standard for IoT or the CAN-bus system in cars. I'm considering focusing on something like Apple keychain, Firefox password storage, a messaging protocol like WhatsApp or Telegram, or even an IoT protocol. By conducting a formal analysis, I hope to uncover potential mistakes in the protocol's design or implementation, contributing to its improvement."
Alessandro,Bruni,"I want to dive into analyzing and compiling secure protocols. Many tools out there struggle with limitations, like not being able to automatically check certain properties, which means manual work is often needed to complete proofs. Some equations also need special attention. I'm particularly interested in tackling the challenges of stateful protocols, which depend on maintaining state to enable specific actions. Another key area I'd like to explore is how to build secure software once a protocol model is proven correct. One approach could be deriving secure code directly from the protocol model. I'm passionate about programming languages, software analysis, logic, and compilers, and I believe addressing security issues is crucial in today's software landscape."
Bernardo Machado,David,"I want to explore how cryptocurrencies and smart contracts can offer privacy without compromising legal requirements. Most current systems don't guarantee privacy, letting anyone see transaction details. While some solutions aim for full anonymity, they’re often too complex and clash with financial laws that require transparency for legal authorities. I’d like to propose security definitions that offer fine-grained privacy, balancing user anonymity with compliance. This involves designing systems that allow for auditing in line with KYC/AML regulations. I’m also interested in using state channels to create more efficient protocols. My project will combine theoretical cryptography with practical implementation, and I’m eager to tailor it to my interests and skills."
Bernardo Machado,David,"I want to explore how we can improve the efficiency of blockchain consensus protocols, which are crucial for cryptocurrencies and smart contracts. Right now, systems like Bitcoin's Proof-of-Work are slow, handling only a few transactions per second. This is a huge bottleneck compared to traditional financial systems that process thousands. My goal is to find ways to make blockchain systems more scalable for real-world applications.

I'm considering a few approaches. One idea is blockchain sharding, where multiple parallel blockchains are maintained by different user groups but still stay consistent with each other. Another is using sidechains for heavy smart contracts, which would offload transactions to a secondary chain while keeping everything in sync with the main one. I'm also interested in exploring alternatives to Proof-of-Work, like Proof-of-Stake, to boost performance even with a single blockchain instance. This project will involve a lot of theoretical work, but I’m also keen on practical evaluations, especially if I can collaborate with others who have a knack for distributed systems programming."
Bernardo Machado,David,"I want to explore how blockchain consensus protocols and applications, often designed without solid security guarantees, can be vulnerable to attacks. These vulnerabilities can lead to significant financial losses when exploited. My goal is to identify specific weaknesses in these systems, which are mostly open source, using practical vulnerability analysis techniques. Once I find these vulnerabilities, I plan to propose fixes at the protocol level and responsibly share my findings with the development community. This project will involve a lot of code analysis and testing, so a strong programming background will be essential."
Bernardo Machado,David,"I want to explore how we can make Multiparty Computation (MPC) more efficient. MPC lets parties who don’t trust each other compute a program using their private data without revealing anything except the final result. While there are many existing protocols, I’m interested in improving their efficiency for both general computations and specific applications like machine learning on private data. My focus will be on reducing network communication, such as the number of protocol rounds, and cutting down the local computational complexity, like the time each party spends computing messages.

I’d like to work on making general-purpose MPC protocols more efficient by reducing round complexity, which is crucial because long round trips over the internet can be impractical. I also want to improve how protocols for arithmetic circuits integrate with those for boolean circuits, as each is better for different algorithms. Exploring preprocessing, where most computation happens before inputs are known, is another area I’m keen on. Additionally, I’m interested in developing protocols for specific applications, like machine learning, which could be valuable for end-user products and industry solutions. I have a background in modern cryptography and some software development experience, so I’m ready to dive into both the theoretical and practical aspects of this project."
Bernardo Machado,David,"I want to dive into the core of theoretical cryptography by exploring the minimal building blocks needed for complex cryptographic protocols. I'm particularly interested in Commitments and Oblivious Transfer, which are crucial for tasks like Multiparty Computation and Zero-Knowledge Proofs. My goal is to understand the assumptions necessary for constructing these protocols and to explore their efficiency limits. I’d like to investigate how these primitives can be built under different assumptions and push the boundaries of their efficiency. By doing so, I hope to develop more efficient protocols for Commitments and Oblivious Transfer. This project will involve a lot of theoretical work, and I’m ready to tackle it with my background in modern cryptography."
Christian,Hardmeier,"I'm interested in exploring how we can process speech and handle sensitive data, specifically focusing on transcribing and anonymizing sensitive conversations for training large language models. I'm collaborating with the VIRTU research group at Region Hovedstadens Psykiatri to create a dataset from therapist-patient interactions. This dataset will help train models to analyze and support psychotherapy. We have a large collection of audio recordings from therapy sessions, and I want to adapt automatic speech recognition models to work effectively with this data. A key challenge will be ensuring the transcriptions are anonymized by automatically identifying and removing any personally identifiable information."
Christian,Hardmeier,"I want to explore how sensitive uncertainty metrics from language model outputs are to the certainty levels in the data used for fine-tuning. My plan is to create datasets with controlled confidence levels and see how these affect the model's expressed uncertainty. I’m interested in aligning the uncertainty a language model communicates with the numerical uncertainty measured by machine learning methods. Essentially, I want the model's expressed uncertainty to match what it actually 'feels'.

I’ll also dive into the difference between uncertainty of meaning and uncertainty of form. When a language model is uncertain, is it about the facts or just how to phrase them? This distinction is crucial depending on the task, like grammar checking versus question answering. I aim to explore how well we can separate these two types of uncertainty and get reliable estimates for each."
Christian,Hardmeier,"I want to dive into the world of toxic speech and focus on a specific type to understand its unique characteristics. My goal is to create models that can recognize this type of speech and pinpoint exactly what makes it toxic. I'm considering building on past projects about dehumanizing language or threats, but I'm also open to exploring a completely different type of toxic speech. 

I plan to target toxic language aimed at a specific group, like a particular demographic, and develop methods to automatically identify and label the group-specific nature of this toxicity. By doing this, I hope to shed light on how toxic language varies depending on the group it targets and improve our ability to detect and address it."
Christian,Hardmeier,"I want to explore how we handle ambiguity in referring expressions, like when a pronoun could refer to multiple things. For example, in ""The bomb exploded violently. It created a huge crater,"" ""It"" could mean the bomb or the explosion. I aim to model coreference resolution in a way that respects this ambiguity instead of forcing a single interpretation. Additionally, I'm interested in how different languages handle referring expressions. Languages often have unique ways of choosing these expressions, which becomes clear when comparing translations. I plan to develop automatic methods using neural machine translation or large language models to align translations of referring expressions across languages, even when they're not literal."
Dan Witzner,Hansen,"I want to create a new domain-specific language (DSL) that feels like LaTeX but is simpler and still powerful enough for defining macros and organizing content in Jupyter Notebooks. My main goals are to design an easy-to-use syntax using frameworks like Lark for Python to help parse and interpret the DSL. I’d like to enable macro creation and other custom elements so users can build reusable components. It’s important to ensure this DSL works seamlessly with the JupyterBook environment, letting users embed DSL content directly in notebooks while keeping the flexibility of Python and Markdown cells. This will make it easier to share and define content on platforms like iml.itu.dk, allowing for smoother integration of custom structures in Jupyter projects."
Martin,Aumüller,"I want to explore how we can keep user information safe during similarity searches, which is crucial for social networks and big systems. My focus is on privacy issues and techniques to protect data in similarity search systems, which are used in things like recommender systems and machine learning. These systems often deal with sensitive data, such as user preferences or medical records. I plan to look into different attack scenarios on these tools and assess their impact. This involves studying various methods like locality-sensitive hashing and tree-based techniques in their specific applications.

I also want to investigate privacy-preserving techniques for similarity searches and evaluate their security. My goal is to develop a similarity-search library with strong security guarantees. Additionally, I’d like to compare existing methods based on their privacy protection and speed. Building on previous work, I might extend a tool for privacy-preserving similarity search. Alternatively, I could conduct a survey of current technologies in this field."
Michele,Coscia,"I want to explore how cultural data can be analyzed through networks to understand the production of culture. I'm thinking of creating networks like artist-band connections using Discogs data, movie networks from IMDb, or even character networks from books and graphic novels. By building these networks with detailed node metadata, I aim to study various aspects of cultural production. This could include discovering new genre classifications, analyzing cultural eras over time, or examining geographical influences. My goal is to uncover patterns and insights that reveal how culture is produced and evolves."
Michele,Coscia,"I want to explore how to estimate polarization in political discourse on social media, specifically when there are more than two opposing opinions. I've developed a measure for two-sided debates, but I’m curious about handling scenarios where users support multiple political parties. I’d like to use NLP techniques to create word embeddings and apply machine learning methods like PCA, NNMF, or t-SNE. This approach isn’t just for network enthusiasts; it’s about understanding complex political landscapes on platforms like Facebook and Twitter."
Michele,Coscia,"I want to explore how we can use OpenStreetMap data to build urban networks and understand cities better. By diving into the rich data about points of interest, I aim to characterize cities based on the diversity of their amenities. This could lead to creating innovative livability scores that reflect how vibrant and varied a city is. My approach involves analyzing the data to see how different amenities are distributed and connected, which could offer fresh insights into urban planning and development."
Michele,Coscia,"I want to explore how where you live affects your wealth, using a new dataset that estimates development levels in developing countries. I'm curious about the link between a person's location and their economic status. Additionally, I’d like to investigate how lockdowns impact people's livelihoods. Specifically, I want to find out if making human mobility more difficult affects everyone equally or if it hits low-income communities harder."
Michele,Coscia,"I want to create a network analysis library using Torch, focusing on GPU computing. While Torch Geometric offers some great graph learning functions, I think there's room to build a more comprehensive library from scratch that fully leverages GPU power. My plan is to implement and test several network analysis functions, aiming for a robust tool that enhances what’s currently available. This project excites me because it combines my interest in network analysis with cutting-edge GPU technology, and I believe it could really benefit researchers and developers working with large-scale graphs."
Michele,Coscia,"I want to explore whether I can generate a new network from scratch using a set of connection rules derived from an existing network. My idea is to start with an algorithm that identifies these underlying rules by analyzing frequent patterns in the original network. Then, I’d like to see if applying these rules can create a new network that resembles the original one. This involves testing if the generated network maintains similar characteristics and structure. My goal is to understand if the rules alone are enough to recreate the essence of the original network."
Patrick,Bahr,"I want to create a functional reactive programming language embedded within an existing language like Haskell, F#, or Scala. My goal is to cleverly use the host language's type system to represent the reactive language's types. This approach allows programs in my new language to leverage the host language's features and libraries, making it both powerful and versatile."
Patrick,Bahr,"I want to create a compiler for a functional reactive programming language. This project will let me dive into building the parser, type checker, and code generator. I’m excited about the freedom to experiment with different features like type inference, optimizations, and advanced type system elements. I could also explore efficient memory management techniques. If the scope gets too broad, I might focus on just one aspect, like type inference, to really hone in on that area."
Patrick,Bahr,"I want to dive into functional reactive programming by building something substantial, like a GUI framework, a game, or a library for smooth animations and visualizations. My goal is to see how the unique type systems in these languages affect the development process. I'm curious about how these non-standard types can shape the way software is created and what challenges or benefits they bring to the table."
Patrick,Bahr,"I want to explore property-based testing, where you write properties your program must satisfy and then use a tool to test these with random inputs. My focus is on creating a tool or library specifically for reactive programming, which is tricky because these programs are so interactive. A big part of my project will be designing a language that makes it easy for programmers to express the properties they want to test."
Patrick,Bahr,"I want to explore how we can create compilers that are correct by design. Compilers are super complex, and even small bugs can mess up any software built with them. Traditional testing often misses these bugs, so I'm interested in formally verifying that a compiler works as it should. My idea is to derive the compiler directly from its specification, using a series of calculation steps, much like simplifying algebraic expressions. To make this process less error-prone, I plan to use tools like Coq or Agda, which help catch mistakes and automate simpler steps. However, these tools can be cumbersome and hard to follow. So, I aim to develop a tool that can check and partially automate the process of deriving compilers from their specifications, making it more efficient and user-friendly."
Peter,Sestoft,"I want to develop a type system for sheet-defined functions in spreadsheets, specifically focusing on Funcalc. My goal is to enhance both the safety and performance of these functions by eliminating the need to box values during function calls. This should streamline operations and make the process more efficient. There's been some promising groundwork laid by Poul Broennum, and I’d like to build on that to push this idea further."
Peter,Sestoft,"I want to dive into the world of GPGPUs, those super-fast graphics cards that can outpace typical CPUs by 10 to 300 times. My plan is to explore how to harness their power for specific numeric computations, like linear algebra. I'll be using special programming techniques and libraries like Nvidia CUDA or OpenCL to make this happen. My goal is to implement these computations, measure their performance, and fine-tune them for maximum speed."
Peter,Sestoft,"I want to explore how to make the C5 generic collection library for C#/.Net 2.0 more efficient by focusing only on the parts that are actually needed for specific tasks. The library is packed with features like sublist views and persistent trees, but this can lead to unnecessary memory use when not all features are required. My goal is to figure out how to automatically generate or select just the relevant components—like classes, methods, and fields—based on what a program actually uses. This way, I can help reduce memory consumption and speed up the library's performance."
Peter,Sestoft,"I'm interested in exploring how run-time code generation can be applied in Java or C#. Both the Java/JVM platform and the C#/CLR/.Net platform offer great support for generating and executing bytecode on the fly. This capability can lead to exciting new ways to implement things like serialization/deserialization, communication protocols, encryption, and even image transformation and analysis algorithms. I want to dive into these possibilities and see how they can be leveraged to enhance performance and flexibility in these areas."
Rob,van der Goot,"I want to explore how an NLP model can learn from diverse datasets by understanding the origin of the text. When training on data from different sources, it might help the model if it knows where each piece of text comes from. I’d like to try a few methods to incorporate this information. One idea is to use dataset embeddings, like adding a special start token such as [SOCIAL] or [NEWS]. Another approach is to have the model predict the text's origin as a side task. These methods have shown promise individually, but they haven’t been consistently compared. I’m excited to see how they stack up against each other."
Rob,van der Goot,"I want to explore how we can improve lexical normalization, which is all about converting non-standard language into standard language at the word level. Most of the research so far has focused on Twitter, but I’m curious about how these models perform on other types of non-standard language. I’d like to investigate two main questions: how does the performance of these models drop when applied to different domains, and how can we create more robust models that handle a variety of non-standard language? I plan to collect and annotate data for this project, and luckily, the annotation process is relatively quick. I’ll be using existing datasets like MultiLexNorm to guide my work."
Rob,van der Goot,"I want to explore how we can use agents to adapt children's cartoons for language learning in a culturally aware way. Cartoons are fantastic for picking up a new language, but they're usually only available in a few languages. Translating them into others is costly because it involves understanding context, doing culturally sensitive translations, and using text-to-speech technology. I plan to use specific NLP models, or agents, for each of these tasks. A big challenge will be evaluating the results, and I think human feedback will be crucial for that."
Rob,van der Goot,"I want to explore how sequence-to-sequence (seq2seq) models stack up against sequence classification models. Recent studies suggest that seq2seq models can match the performance of sequence classification models by converting tasks into sequence generation tasks. However, these comparisons aren't straightforward. I'm interested in directly comparing an auto-encoder language model with a generative one to see how they really measure up. My goal is to uncover the true potential of seq2seq models for tasks like sequence tagging and structure parsing."
Rob,van der Goot,"I want to explore how NLP models can better understand cultural dimensions, which they typically struggle with. My idea is to predict cultural dimensions, like those from Hofstede, using text analysis. I’d like to see if incorporating this cultural information during the training and prediction phases can improve model performance. This approach could open up new ways to enhance how NLP models interpret cultural contexts."
Rob,van der Goot,"I want to explore how temperature settings affect the human-like quality of text generated by language models. Temperature is a key factor that influences the randomness and style of the output. My goal is to see how different temperature levels impact the perceived human-ness of the text, as judged by people. I'll generate text using various decoding methods with Transformers to get a range of outputs. By comparing these, I hope to understand how to make AI-generated text sound more natural and human-like."
Rob,van der Goot,"I want to explore early stopping strategies in training neural models for NLP. Typically, a development split is used to decide when to stop, but this approach has its downsides. I've come across alternative strategies, like training for a set number of steps or monitoring train loss, but I haven't found any direct comparisons of these methods. I'm interested in seeing how these strategies stack up against each other, especially in the context of cross-lingual transfer. My goal is to find out which method helps pretrained models learn their intended tasks more effectively."
Rob,van der Goot,"I want to explore how sociodemographic factors influence language use. While recent studies show that knowing where a text comes from can boost NLP task performance, it's still unclear which specific attributes like age, gender, or other demographics really impact language. I'm interested in diving into social media data annotations to uncover more insights. For instance, there are intriguing findings about gender differences in syntax, like how women and men might use grammar differently. I’d like to investigate these variations further, especially across different languages and age groups, to see how they play out in real-world language use."
Rob,van der Goot,"I want to explore how instruction tuning works for languages other than English, especially since most datasets are in English. For other languages, we often rely on translated instructions or those generated by advanced language models. However, there's no clear comparison of these methods. I'd like to investigate how much data is needed and the costs involved in creating datasets using these different approaches."
Rob,van der Goot,"I want to explore multi-lingual lexical normalization, which is all about converting social media language into its standard form. Most research focuses on just one language, but I’m interested in using the MultiLexNorm dataset, which covers 13 language variants. While previous models trained separately for each language, I believe using a multi-lingual or cross-lingual approach could boost efficiency and performance. This method might even help with languages that lack annotated data. My goal is to see if these models can transfer knowledge across languages, making the process more versatile and effective."
Rob,van der Goot,"I want to tackle the challenge of tokenizing social media text, which isn't as straightforward as it is for standard domains. My goal is to create a multilingual corpus and model specifically for this task. I'll start by gathering the original utterances from Multi-LexNorm and then develop a gold standard dataset using both the original and tokenized data. I plan to evaluate existing tokenizers and also train my own to see how they perform. This project will build on related work like Universal Word Segmentation and tools like nltk's TweetTokenizer."
Rob,van der Goot,"I want to tackle the challenge of language identification across a vast number of languages, using the LTI LangID Corpus, which includes over 1300 languages. While language identification is often seen as a solved problem, most classifiers only handle about 100 languages and aren't always accessible. My goal is to figure out how to efficiently manage such a large label space and the diverse input features that come with it. I'll explore existing methods like non-linear mapping and compact models for language identification, especially in complex scenarios like code-mixed text. This project aims to push the boundaries of what's possible in language ID, making it more inclusive and effective for a wider range of languages."
Rob,van der Goot,"I want to explore how well language identification models perform across different domains. Most models are usually trained and tested within a single domain, but I think it's important to see how they hold up when applied to varied datasets. I plan to compile a cross-domain dataset to test the robustness of these models. There are already some great resources out there, like datasets from Twitter messages, news summarization, and even Fandom Wikis. By using these, I aim to evaluate and improve the adaptability of language identification models across different types of content."
Rob,van der Goot,"I want to explore dependency parsing for Danish social media data. This involves figuring out the syntactic relationships between words in a sentence. While many languages have been covered by the Universal Dependencies project, performance drops for those not included. I've got some non-standard data samples, called DaN+, and I'm curious about how well current methods work on them. My plan is to annotate a small sample of Danish social media data to test different parsers. I’d like to try various approaches to adapt the parser, inspired by challenges in annotating and parsing mixed-language data, cross-lingual parsing techniques, and methods for low-resource languages. This project will help me understand how to handle input uncertainty in neural network dependency parsing."
Rob,van der Goot,"I want to explore the best strategies for morphological tagging, which involves assigning labels to words based on their structure. Each word can have multiple labels, and I’m curious about which methods work best in different scenarios. I plan to use the Universal Dependencies data, which provides morphological tags for various languages. I’m considering using the MaChAmp toolkit or creating my own BiLSTM tagger. I’ll evaluate at least three common strategies: treating the tags as a single label (similar to POS tagging but with more labels), predicting tags as a sequence (like machine translation), and viewing it as a multilabel prediction problem where each label gets a probability and a cutoff threshold is applied. This project will help clarify which approach is most effective for different situations."
Rodrigo Moreno,Garcia,"I'm excited to explore large-scale co-evolution in a massively multi-agent game environment for my thesis. I want to use the Neural MMO platform to see how thousands or even millions of neural network-controlled agents evolve together. My main question is: under what conditions do interesting group dynamics emerge? I'm curious about what environmental factors might lead these agents to form distinct species or decide to collaborate. By tweaking the environment and observing the agents' interactions, I hope to uncover the drivers behind these complex behaviors."
Rune Møller,Jensen,"I want to tackle the challenge of optimizing container vessel stowage planning. The problem's complexity makes finding an optimal solution tough, so my goal is to create fast and accurate approximation algorithms. I'm excited to explore various techniques like heuristics, large neighborhood search, symbolic representations, integer programming, and hierarchical decompositions to achieve this."
